{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\lenovo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data(42000,785)\n",
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0       0    ...            0         0         0         0         0   \n",
      "1       0    ...            0         0         0         0         0   \n",
      "2       0    ...            0         0         0         0         0   \n",
      "3       0    ...            0         0         0         0         0   \n",
      "4       0    ...            0         0         0         0         0   \n",
      "\n",
      "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0         0  \n",
      "1         0         0         0         0         0  \n",
      "2         0         0         0         0         0  \n",
      "3         0         0         0         0         0  \n",
      "4         0         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "这些参数是根据经验以及结果来调整的，此参数组合可以让准确率到0.99\n",
    "'''\n",
    "#神经网络的学习率，先初始化为1e-4。\n",
    "LEARNING_RATE = 1e-4\n",
    "#迭代的次数\n",
    "TRAINING_ITERATIONS = 2500\n",
    "#后期使用dropout算法来防止过拟合，dropout值选择0.5,说明一层神经元会有一半将被屏蔽，使其激活址值为0。\n",
    "DROPOUT = 0.5\n",
    "#每50个样本用于计算梯度下降算法。\n",
    "BATCH_SIZE = 50\n",
    "#验证集的大小,此处取了整个train.csv的5%的大小，是后期调参调出来的，开始一般取10%-25%，慢慢降低比例。\n",
    "VALIDATION_SIZE = 2000\n",
    "#显示第十张图片。\n",
    "IMAGE_TO_DISPLAY = 10\n",
    "\n",
    "#读入训练集，在这之前要将csv保存为utf-8格式，否则会出现中文乱码的问题。\n",
    "data = pd.read_csv(r'C:\\Users\\Lenovo\\Desktop\\Data_Recognizer-master\\train.csv')\n",
    "#查看数据集有多少行多少列，显示数据集的前五行。\n",
    "print('data({0[0]},{0[1]})'.format(data.shape))\n",
    "print (data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images(42000,784)\n"
     ]
    }
   ],
   "source": [
    "#一行代表一张图，从第一列开始获取数据，因为第0列是\"label\"，即准确的是数字几的结果。不作为训练的数据，只用作结果的比对。\n",
    "images = data.iloc[:,1:].values\n",
    "images = images.astype(np.float)\n",
    "''' convert from [0:255] => [0.0:1.0]。\n",
    "    经过统计，最大的pixel为255，所以给images矩阵都乘以1.0 / 255.0来进行处理。\n",
    "    图像像素在0-255之间为灰度图像，我们的图像已经是灰度图像了，但由于数量很大，为了节省空间，把0-255压缩在0-1之间做处理。\n",
    "    之所以不映射二值图像图像，是因为信息损失太大，只有0，1两个数字，会造成判断的错误。\n",
    "'''\n",
    "images = np.multiply(images, 1.0 / 255.0)\n",
    "#查看一下现在有多少张图片\n",
    "print('images({0[0]},{0[1]})'.format(images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size => 784\n",
      "image_width => 28\n",
      "image_height => 28\n"
     ]
    }
   ],
   "source": [
    "#images的shape属性现在为[42000，784]，所以images.shape[1]为784。即有42000张图片，每张有784个piexel来描述。\n",
    "image_size = images.shape[1]\n",
    "print ('image_size => {0}'.format(image_size))\n",
    "# 一张图片，是用28*28=784个像素来表示的，即一个边长为28的正方形，所以image_width = image_height = 28。\n",
    "image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)\n",
    "print ('image_width => {0}\\nimage_height => {1}'.format(image_width,image_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 将其中一个图像画出来，观察一下样子。\n",
    "def display(img):\n",
    "    # (784) => (28,28)\n",
    "    #将img矩阵从一行784列重塑成28行28列。\n",
    "    one_image = img.reshape(image_width, image_height)\n",
    "    #不显示坐标尺寸。\n",
    "    plt.axis('off')\n",
    "    plt.imshow(one_image, cmap=cm.binary)\n",
    "'''这里的binary，是以二进制的形式呈现图像。背景为白色，像素值越接近于1，就越黑，越接近于0越白\n",
    "   我将binary改变成gray后，全部的黑白色都反转了。\n",
    "'''\n",
    "#显示第十个图片，查源数据可知应该显示数字'8'。\n",
    "display(images[IMAGE_TO_DISPLAY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_flat(42000)\n",
      "labels_flat[10] => 8\n",
      "labels_count => 10\n"
     ]
    }
   ],
   "source": [
    "'''ravel()函数返回的是这一列的视图，改变labels_flat的值时，原始的'label'也会改变。\n",
    "   如果不想改变原始的'label'，则这里可以使用flatten()。\n",
    "   labels_flat在这里存放的是结果集，即判断前面images是哪个数字。\n",
    "'''\n",
    "labels_flat = data['label'].values.ravel()\n",
    "#一共有42000个图片。\n",
    "print('labels_flat({0})'.format(len(labels_flat)))\n",
    "#试着去查找第十个数，看输出是否为8。\n",
    "print ('labels_flat[{0}] => {1}'.format(IMAGE_TO_DISPLAY,labels_flat[IMAGE_TO_DISPLAY]))\n",
    "#统计有多少类数字，输出结果为10，即总共有十个数字，0-9。\n",
    "labels_count = np.unique(labels_flat).shape[0]\n",
    "print('labels_count => {0}'.format(labels_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels(42000,10)\n",
      "labels[10] => [0 0 0 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "'''convert class labels from scalars to one-hot vectors\n",
    "   0 => [1 0 0 0 0 0 0 0 0 0]\n",
    "   1 => [0 1 0 0 0 0 0 0 0 0]\n",
    "   ...\n",
    "   9 => [0 0 0 0 0 0 0 0 0 1]\n",
    "   将结果集进行one-hot编码，具体见上面的注释说明。\n",
    "'''\n",
    "'''\n",
    "要进行one-hot编码是因为要与最后计算结果做对比，如果只是一个数字的话，不能对比是否相同。\n",
    "'''\n",
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "labels = dense_to_one_hot(labels_flat, labels_count)\n",
    "labels = labels.astype(np.uint8)\n",
    "test = 'labels({0[0]},{0[1]})'.format(labels.shape)\n",
    "print('labels({0[0]},{0[1]})'.format(labels.shape))\n",
    "print ('labels[{0}] => {1}'.format(IMAGE_TO_DISPLAY,labels[IMAGE_TO_DISPLAY]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images(40000,784)\n",
      "validation_images(2000,784)\n"
     ]
    }
   ],
   "source": [
    "# 划分训练集和验证集。\n",
    "'''由于前期不知道到底验证集要设定为多少，所以这里采用宏定义好调参。\n",
    "   images属于narray结构，[行,列]。\n",
    "   images[0]就表示images矩阵的第0行。\n",
    "   images[:2]表示从最开始的第0行引用到第2行，即引用0，1行。（注意这里不包括第二行）\n",
    "   images[2:]表示从第二行开始一直到最后。（这里包括第二行）\n",
    "   只要后面没有逗号，都表示的是行。\n",
    "'''\n",
    "'''\n",
    "   images[:,0]表示第0列（注意逗号和冒号）\n",
    "   我们这里取的验证集validation_images是images的前VALIDATION_SIZE行，即取VALIDATION_SIZE个图片。\n",
    "   取的训练集为images的VALIDATION_SIZE后面的所有行，即42000-VALIDATION_SIZE个图片。\n",
    "'''\n",
    "#同时取images（像素集合）和labels（对应的数字结果）\n",
    "validation_images = images[:VALIDATION_SIZE]\n",
    "validation_labels = labels[:VALIDATION_SIZE]\n",
    "train_images = images[VALIDATION_SIZE:]\n",
    "train_labels = labels[VALIDATION_SIZE:]\n",
    "'''\n",
    "   train_images({0[0]},{0[1]})这种写法是通过下标来进行映射。由于我们不知道train_images.shape里面具体有什么，只能通过下标来获取。\n",
    "'''\n",
    "print('train_images({0[0]},{0[1]})'.format(train_images.shape))\n",
    "print('validation_images({0[0]},{0[1]})'.format(validation_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化权重\n",
    "'''\n",
    "    tf.truncated_normal产生正态分布的一个函数，shape表示生成张量的维度，mean是均值，这里等于0，stddev是标准差这里为0.1   \n",
    "    这个函数产生的随机数与均值的差距不会超过两倍的标准差。\n",
    "'''\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    #构造initial实例添加到图中\n",
    "    return tf.Variable(initial)\n",
    "#初始化偏值\n",
    "def bias_variable(shape):\n",
    "    #创建一个常量tensor，赋值为0.1，其形状为shape。\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#卷积函数\n",
    "'''\n",
    "    tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, name=None)\n",
    "    input：需要做卷积的输入图像。它要求是一个Tensor，具有[batch, in_height, in_width, in_channels]这样的shape，\n",
    "                                                [训练时一个batch的图片数量, 图片高度, 图片宽度, 图像通道数]\n",
    "           注意这是一个4维的Tensor，要求类型为float32和float64其中之一\n",
    "    \n",
    "    filter：CNN中的卷积核。它要求是一个Tensor，具有[filter_height, filter_width, in_channels, out_channels]这样的shape，\n",
    "                                            [卷积核的高度，卷积核的宽度，图像通道数，卷积核个数]\n",
    "            要求类型与参数input相同，有一个地方需要注意，第三维in_channels，就是参数input的第四维\n",
    "    strides：卷积时在图像每一维的步长，这是一个一维的向量，长度4\n",
    "    padding：string类型的量，只能是\"SAME\",\"VALID\"其中之一，这个值决定了不同的卷积方式。在边缘上的取样影响Conv层的面积，由于移动步长不一定能整除整张图的像素宽度，\n",
    "             不越过边缘取样会得到Valid Padding， 越过边缘取样会得到Same Padding\n",
    "    use_cudnn_on_gpu：bool类型，是否使用cudnn加速，默认为true\n",
    "    name：指定该操作的名称\n",
    "    具体如何进行卷积，请查看我的博客：http://blog.csdn.net/memoryjdch/article/details/75646487\n",
    "'''\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooling：在卷积之后的操作。将不同Stride的卷积用某种方式合并起来，节省卷积层的空间复杂度。\n",
    "'''\n",
    "    tf.nn.max_pool(value, ksize, strides, padding, name=None)\n",
    "    value：需要池化的输入，一般池化层接在卷积层后面，所以输入通常是feature map，依然是[batch, height, width, channels]这样的shape。\n",
    "    ksize：池化窗口的大小，取一个四维向量，一般是[1, height, width, 1]，因为我们不想在batch和channels上做池化，所以这两个维度设为了1。\n",
    "    strides：和卷积类似，窗口在每一个维度上滑动的步长，一般也是[1, stride,stride, 1]。\n",
    "    padding：和卷积类似，可以取'VALID' 或者'SAME'。\n",
    "    返回一个Tensor，类型不变，shape仍然是[batch, height, width, channels]这种形式。\n",
    "'''\n",
    "'''\n",
    "    我们这里是要用2*2的窗口来池化x，选择4个数中最大的那个，步长为2。\n",
    "    例如：\n",
    "    [[0,3],[4,2]] => 4\n",
    "    [[0,1],[1,1]] => 1\n",
    "'''\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#神经网络的输入与输出\n",
    "#创建图像的占位符，这里的None表示可以可以改变的，不固定的值\n",
    "x = tf.placeholder('float', shape=[None, image_size])\n",
    "#创建结果的占位符\n",
    "y_ = tf.placeholder('float', shape=[None, labels_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 1)\n",
      "(?, 28, 28, 32)\n",
      "(?, 14, 14, 32)\n"
     ]
    }
   ],
   "source": [
    "#第一层卷积网络\n",
    "'''\n",
    "    一个权重矩阵和一个bias组成了一个kernel。一个kernel检测图片的一个特征。如果想要全方位的获取图片信息，则需要多个kernel\n",
    "'''\n",
    "#[5,5,1,32]表示用5*5的权重矩阵来计算图像的32个特性。1表示是灰度图像。\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "#每个输出通道分量的偏置矢量为32\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "\n",
    "'''\n",
    "    将图像转化为tensorflow格式，并重新表示为(40000,784) => (40000,28,28,1)\n",
    "    -1代表的含义是不用我们自己指定这一维的大小，函数会自动计算，但列表中只能存在一个-1。\n",
    "'''\n",
    "image = tf.reshape(x, [-1,image_width , image_height,1])\n",
    "print (image.get_shape())\n",
    "\n",
    "\n",
    "'''\n",
    "    ReLU（Rectified Linear unit）激活函数最近变成了神经网络中隐藏层的默认激活函数。\n",
    "    这个简单的函数包含了返回max(0,x)，对于负值，它会返回0，其它返回x。\n",
    "    我们这里在卷积层后的隐藏层中使用这个激活函数。\n",
    "'''\n",
    "#先卷积再池化\n",
    "h_conv1 = tf.nn.relu(conv2d(image, W_conv1) + b_conv1)\n",
    "print (h_conv1.get_shape()) # => (40000, 28, 28, 32)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "print (h_pool1.get_shape()) # => (40000, 14, 14, 32)\n",
    "\n",
    "# Prepare for visualization\n",
    "# 以4*8的格式来显示32个特征\n",
    "layer1 = tf.reshape(h_conv1, (-1, image_height, image_width, 4 ,8))# => (40000, 28, 28, 4，8)\n",
    "# 重新排序，让4和8处在前面，对应的x和y在后面\n",
    "layer1 = tf.transpose(layer1, (0, 3, 1, 4, 2))# 0,3,1,4,2对应=> (40000, 4, 28, 8, 28)\n",
    "layer1 = tf.reshape(layer1, (-1, image_height*4, image_width*8))# => (40000, 112, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 14, 14, 64)\n",
      "(?, 7, 7, 64)\n"
     ]
    }
   ],
   "source": [
    "#  第二层卷积网络\n",
    "#权重矩阵还是5*5，这里第二层网络的通道32，对应的是第一层网络的32个特征。64为输出通道的数量。\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "#偏移量为64\n",
    "b_conv2 = bias_variable([64])\n",
    "#由于我们现在是要将第一层的结果（h_pool1）进行卷积，它已经是tensorflow格式的，不用再进行格式的转换。\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "print (h_conv2.get_shape()) # => (40000, 14,14, 64)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "print (h_pool2.get_shape()) # => (40000, 7, 7, 64)\n",
    "#Prepare for visualization\n",
    "#以4*16的格式来显示64个特征\n",
    "layer2 = tf.reshape(h_conv2, (-1, 14, 14, 4 ,16))\n",
    "#重新排序，让4和16处在前面，对应的x和y在后面\n",
    "layer2 = tf.transpose(layer2, (0, 3, 1, 4,2))\n",
    "layer2 = tf.reshape(layer2, (-1, 14*4, 14*16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1024)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    经过第一二层的处理，图片大小由原来的28*28变成了7*7，且有64个特征值。\n",
    "    这一步我们添加一个有1024个神经元的紧密连接层，每个神经元都连接到上一层的输出\n",
    "'''\n",
    "# 建立紧密连接层\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "# 把h_pool2_flat的结构从(40000, 7, 7, 64)变为(40000, 3136)\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "print (h_fc1.get_shape())\n",
    "# => (40000, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-8d6f157a7974>:5: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    使用dropout技术，主要是为了防止过拟合。dropout主要是减少有效参数的数量\n",
    "'''\n",
    "keep_prob = tf.placeholder('float')\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    添加softmax层。softmax模型可以用来给不同的对象分配概率。\n",
    "    比如我们判断一张图片是9的概率为80%，判断为8的概率为5%，这个概率就是softmax分配的。\n",
    "'''\n",
    "# readout layer for deep net\n",
    "W_fc2 = weight_variable([1024, labels_count])\n",
    "b_fc2 = bias_variable([labels_count])\n",
    "y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "print (y.get_shape())\n",
    "# => (40000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    为了训练我们的模型，我们首先需要定义一个指标来评估这个模型是好的。\n",
    "    在机器学习中，我们通常定义指标来表示一个模型是坏的，这个指标称为成本（cost）或损失（loss），然后尽量最小化这个指标。\n",
    "'''\n",
    "#损失函数：交叉熵\n",
    "'''\n",
    "    交叉熵可在神经网络(机器学习)中作为损失函数，p表示真实标记的分布，q则为训练后的模型的预测标记分布，交叉熵损失函数可以衡量p与q的相似性。\n",
    "    交叉熵作为损失函数还有一个好处是使用sigmoid函数在梯度下降时能避免均方误差损失函数学习速率降低的问题，因为学习速率可以被输出的误差所控制。\n",
    "    这里的交叉熵不仅仅用来衡量单一的一对预测和真实值，而是所有100幅图片的交叉熵的总和。\n",
    "    对于100个数据点的预测表现比单一数据点的表现能更好地描述我们的模型的性能。\n",
    "    如果想要更深入地理解交叉熵，请移步：http://colah.github.io/posts/2015-09-Visual-Information/\n",
    "    如果想要通俗地理解交叉熵，请移步：https://www.zhihu.com/question/41252833的Agenter的回答\n",
    "'''\n",
    "#reduce_sum()计算所有元素的总和\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构造优化器\n",
    "'''\n",
    "    构造优化器AdamOptimizer，以LEARNING_RATE=1e-4的学习速率最小化交叉熵。\n",
    "    这里本来是用梯度下降优化器的train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "    但是我们用更复杂的Adam算法来代替梯度下降，结果更加准确。\n",
    "'''\n",
    "train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#评价模型\n",
    "'''\n",
    "    tf.argmax(y,1)意思是按行计算y中的最大值\n",
    "    tf.equal(A,B)表示比较A，B对应元素是否相同，如果相同，返回true，否则返回false。返回的结构与A相同。\n",
    "    tf.cast()函数是将correct_prediction的类型转化为float\n",
    "    tf.reduce_mean求correct_prediction的平均值作为模型最终的的准确率\n",
    "'''\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#预测函数。取10个概率中最大的作为预测，例如：\n",
    "#[0.1, 0.9, 0.2, 0.1, 0.1 0.3, 0.5, 0.1, 0.2, 0.3] => 1\n",
    "predict = tf.argmax(y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练、验证和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练、验证和预测\n",
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "num_examples = train_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#按照批次提供数据\n",
    "'''\n",
    "    关于batch_size、epochs、interations的说明：\n",
    "    如果一个训练集中有1000条数据，每10条数据迭代一次，要迭代100次。\n",
    "    那么batche_size=10，interations=100，每迭代完1000条数据，epochs=1\n",
    "'''\n",
    "def next_batch(batch_size):\n",
    "    # 要进行训练的图像\n",
    "    global train_images\n",
    "    #要进行训练的结果\n",
    "    global train_labels\n",
    "    #当前训练的样本数\n",
    "    global index_in_epoch\n",
    "    #epochs计数\n",
    "    global epochs_completed\n",
    "\n",
    "    #从0开始，每调用一次函数就增加50个样本\n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "\n",
    "    # 当所有的训练集都被使用时, 再重新随机排序\n",
    "    if index_in_epoch > num_examples:\n",
    "        #每全部训练完一次，epoch+1\n",
    "        epochs_completed += 1\n",
    "        #迭代完之后，打乱数据\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        train_images = train_images[perm]\n",
    "        train_labels = train_labels[perm]\n",
    "        #重新开始下一轮epochs\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "        #断言：如果batch_size超出了数据集的范围，则返回异常\n",
    "        assert batch_size <= num_examples\n",
    "    end = index_in_epoch\n",
    "    #每50个取一次，同时取图像和结果\n",
    "    return train_images[start:end], train_labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化变量，开始TensorFlow session\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy / validation_accuracy => 0.10 / 0.06 for step 0\n",
      "training_accuracy / validation_accuracy => 0.16 / 0.12 for step 1\n",
      "training_accuracy / validation_accuracy => 0.24 / 0.14 for step 2\n",
      "training_accuracy / validation_accuracy => 0.08 / 0.22 for step 3\n",
      "training_accuracy / validation_accuracy => 0.18 / 0.20 for step 4\n",
      "training_accuracy / validation_accuracy => 0.16 / 0.20 for step 5\n",
      "training_accuracy / validation_accuracy => 0.12 / 0.24 for step 6\n",
      "training_accuracy / validation_accuracy => 0.20 / 0.26 for step 7\n",
      "training_accuracy / validation_accuracy => 0.18 / 0.28 for step 8\n",
      "training_accuracy / validation_accuracy => 0.20 / 0.30 for step 9\n",
      "training_accuracy / validation_accuracy => 0.20 / 0.30 for step 10\n",
      "training_accuracy / validation_accuracy => 0.50 / 0.52 for step 20\n",
      "training_accuracy / validation_accuracy => 0.60 / 0.56 for step 30\n",
      "training_accuracy / validation_accuracy => 0.58 / 0.74 for step 40\n",
      "training_accuracy / validation_accuracy => 0.68 / 0.76 for step 50\n",
      "training_accuracy / validation_accuracy => 0.70 / 0.80 for step 60\n",
      "training_accuracy / validation_accuracy => 0.84 / 0.88 for step 70\n",
      "training_accuracy / validation_accuracy => 0.78 / 0.90 for step 80\n",
      "training_accuracy / validation_accuracy => 0.84 / 0.86 for step 90\n",
      "training_accuracy / validation_accuracy => 0.86 / 0.88 for step 100\n",
      "training_accuracy / validation_accuracy => 0.94 / 0.90 for step 200\n",
      "training_accuracy / validation_accuracy => 0.90 / 0.90 for step 300\n",
      "training_accuracy / validation_accuracy => 0.88 / 0.94 for step 400\n",
      "training_accuracy / validation_accuracy => 0.98 / 0.92 for step 500\n",
      "training_accuracy / validation_accuracy => 0.96 / 0.92 for step 600\n",
      "training_accuracy / validation_accuracy => 0.90 / 0.90 for step 700\n",
      "training_accuracy / validation_accuracy => 0.96 / 0.92 for step 800\n",
      "training_accuracy / validation_accuracy => 0.98 / 0.94 for step 900\n",
      "training_accuracy / validation_accuracy => 0.98 / 0.94 for step 1000\n",
      "training_accuracy / validation_accuracy => 1.00 / 0.98 for step 2000\n",
      "training_accuracy / validation_accuracy => 1.00 / 0.98 for step 2499\n"
     ]
    }
   ],
   "source": [
    "#让变量可视化\n",
    "#用来存放训练集准确率\n",
    "train_accuracies = []\n",
    "#用来存放验证集准确率\n",
    "validation_accuracies = []\n",
    "#存储i\n",
    "x_range = []\n",
    "#每迭代一步就显示一次\n",
    "display_step = 1\n",
    "\n",
    "for i in range(TRAINING_ITERATIONS):\n",
    "\n",
    "    # get new batch\n",
    "    #batch_xs存储的是图像的50个样本，batch_ys存储的是结果的50个样本\n",
    "    batch_xs, batch_ys = next_batch(BATCH_SIZE)\n",
    "\n",
    "    # check progress on every 1st,2nd,...,10th,20th,...,100th... step\n",
    "    if i % display_step == 0 or (i + 1) == TRAINING_ITERATIONS:\n",
    "        #计算训练集准确率：把accuracy这个tensor用feed_dict这样的数据去flow它并打印出来。\n",
    "        #eval函数相当于执行一次run函数\n",
    "        #keep_prob: 1.0 表示这里不用dropout神经元\n",
    "        train_accuracy = accuracy.eval(feed_dict={x: batch_xs,\n",
    "                                                  y_: batch_ys,\n",
    "                                                  keep_prob: 1.0})\n",
    "        if (VALIDATION_SIZE):\n",
    "            validation_accuracy = accuracy.eval(feed_dict={x: validation_images[0:BATCH_SIZE],\n",
    "                                                           y_: validation_labels[0:BATCH_SIZE],\n",
    "                                                           keep_prob: 1.0})\n",
    "            print('training_accuracy / validation_accuracy => %.2f / %.2f for step %d' % (\n",
    "            train_accuracy, validation_accuracy, i))\n",
    "\n",
    "            validation_accuracies.append(validation_accuracy)\n",
    "\n",
    "        else:\n",
    "            print('training_accuracy => %.4f for step %d' % (train_accuracy, i))\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        x_range.append(i)\n",
    "\n",
    "        # 如果大于10的话就每10步显示一次\n",
    "        if i % (display_step * 10) == 0 and i:\n",
    "            display_step *= 10\n",
    "    # 每50个样本对整个图train_step进行训练，dropout率为0.5\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys, keep_prob: DROPOUT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_accuracy => 0.9820\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#在验证集上检查准确率，并画出每一步的准确率\n",
    "if(VALIDATION_SIZE):\n",
    "    validation_accuracy = accuracy.eval(feed_dict={x: validation_images,\n",
    "                                                   y_: validation_labels,\n",
    "                                                   keep_prob: 1.0})\n",
    "    print('validation_accuracy => %.4f'%validation_accuracy)\n",
    "    plt.plot(x_range, train_accuracies,'-b', label='Training')\n",
    "    plt.plot(x_range, validation_accuracies,'-g', label='Validation')\n",
    "    plt.legend(loc='lower right', frameon=False)\n",
    "    plt.ylim(ymax = 1.1, ymin = 0.7)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('step')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_images(28000,784)\n"
     ]
    }
   ],
   "source": [
    "#在测试集上面运行模型并观察结果\n",
    "#读入测试集\n",
    "test_images = pd.read_csv(r'C:\\Users\\Lenovo\\Desktop\\Data_Recognizer-master\\test.csv').values\n",
    "test_images = test_images.astype(np.float)\n",
    "#跟前面训练集处理数据一样，给每个pixel除以255 convert from [0:255] => [0.0:1.0]\n",
    "test_images = np.multiply(test_images, 1.0 / 255.0)\n",
    "print('test_images({0[0]},{0[1]})'.format(test_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_lables(28000)\n"
     ]
    }
   ],
   "source": [
    "#预测测试集\n",
    "#predicted_lables = predict.eval(feed_dict={x: test_images, keep_prob: 1.0})\n",
    "#按照test.images的结构来创建一个全为0的矩阵\n",
    "predicted_lables = np.zeros(test_images.shape[0])\n",
    "#\"//\"操作为取整操作\n",
    "for i in range(0,test_images.shape[0]//BATCH_SIZE):\n",
    "    #和前面训练集一样，每50个样本进行一次操作\n",
    "    predicted_lables[i*BATCH_SIZE : (i+1)*BATCH_SIZE] = predict.eval(feed_dict={x: test_images[i*BATCH_SIZE : (i+1)*BATCH_SIZE],\n",
    "                                                                                keep_prob: 1.0})\n",
    "print('predicted_lables({0})'.format(len(predicted_lables)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_lables[10] => 5.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#输出预测的结果和图像\n",
    "display(test_images[IMAGE_TO_DISPLAY])\n",
    "print ('predicted_lables[{0}] => {1}'.format(IMAGE_TO_DISPLAY,predicted_lables[IMAGE_TO_DISPLAY]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'submission_softmax.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-9a0755765a36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m            \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ImageId,Label'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m            \u001b[0mcomments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m            fmt='%d')\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mlayer1_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mIMAGE_TO_DISPLAY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mIMAGE_TO_DISPLAY\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1351\u001b[0m         \u001b[1;31m# datasource doesn't support creating a new file ...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1352\u001b[1;33m         \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1353\u001b[0m         \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m         \u001b[0mown_fh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'submission_softmax.csv'"
     ]
    }
   ],
   "source": [
    "# save results\n",
    "np.savetxt('submission_softmax.csv',\n",
    "           np.c_[range(0,len(test_images)),predicted_lables],\n",
    "           delimiter=',',\n",
    "           header = 'ImageId,Label',\n",
    "           comments = '',\n",
    "           fmt='%d')\n",
    "\n",
    "layer1_grid = layer1.eval(feed_dict={x: test_images[IMAGE_TO_DISPLAY:IMAGE_TO_DISPLAY+1], keep_prob: 1.0})\n",
    "plt.axis('off')\n",
    "plt.imshow(layer1_grid[0], cmap=cm.seismic )\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
